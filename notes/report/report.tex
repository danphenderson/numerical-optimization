\documentclass[10pt]{article}

\input{../preamble.tex}
\usepackage{booktabs}
\usepackage{caption}


% ----------------- Document TITLE
% -----------------------------------------------------------------
% ------------------
\title{Classification of Smooth Unconstrained Optimization Problems}
\author{Daniel Henderson}
\date{\today}


% ------------------ DOCUMENT START
% -----------------------------------------------------------------
% ------------------
\begin{document}
\maketitle


% ------------------ ABSTRACT
% -----------------------------------------------------------------
% ------------------
\begin{abstract}
    \noindent
    We study the local convexity properties of a benchmark suite of smooth, 
    unconstrained minimization problems drawn from the 
    \texttt{OptimizationProblems.jl}~\cite{OptimizationProblems} Julia package.
    For each problem, we review its origin, present the analytic form
    of the objective $f:\R^n\!\to\!\R$ and the standard starting point
    $\vct{x}_0$.  We introduce a sampling-based procedure to classify
    the critical-point structure and verify the positive definiteness of
    the Hessian in a neighborhood of a strict local minimizer.  Numerical
    experiments confirm that while some test functions exhibit strong
    local convexity, others contain narrow regions of non-convexity that
    can slow down standard schemes, e.g. (TODO: add "tacking" ref. here and complete
    results statement)
    \noindent\textbf{Keywords:} benchmarking, numerical optimization, stationary points, saddle points,
\end{abstract}



% ------------------ TABLE OF CONTENTS
% -----------------------------------------------------------------
% ------------------
\tableofcontents
\newpage


% ------------------ SECTION: INTRODUCTION
% -----------------------------------------------------------------
% ------------------
\section{Introduction}
    \label{sec:intro}
    \medskip

    Understanding the local convexity of an objective function
    near strict local minimizers is fundamental to the design 
    and convergence analysis of smooth optimization algorithms. 
    Strong local convexity near a minimizer often guarantees rapid 
    convergence of gradient-based and Newton-type methods. In 
    contrast, narrow or nonconvex regions can result in slow progress 
    or convergence to saddle points. We select benchmark problems from the
    \emph{Constrained and Unconstrained Testing Environment} SIF (CUTE)~\cite{CUTE}.
    We sample the objective of each problem to reveal long, 
    narrow valleys of weak/zero curvature surrounding strict minimizers.
    Additinally, we analyze the spectral pattern of the Hessian of $f$ at
    critical points obtained from seeding standard schemes from randomly
    sampled starting locations surrounding each problems initial iterate.
    Moreover, we replicate the findings of Kok et al. for the generalized
    Rosenbrock problem~\cite{Kok2009} and extend their analysis to 
    a larger set of benchmark problems.
  
    \medskip

    Our contributions are:
    \begin{itemize}
        \item literature survey of known techniques for classifying critical points.
        \item a sampling-based classification algorithm for sampling the curvature
        within a neighborhood of $\eps$-first-order stationary points. 
        \item systematically compares the local convexity profiles of standard
        benchmark problems in continuous optimization. (ref artificial article)
        \item supplemental material containing analytical expressions $f$, and the
        accepted initial iterate $\vct{x}_0$, as well as a discussion of
        each problem's provenance and known properties from the literature. 
    \end{itemize}
    
    \medskip

    \textbf{Introduction overview.} Section~\ref{intro:preliminaries} establishes the notation adopted throughout the manuscript.  
    Section~\ref{intro:unc-problem} formulates the smooth unconstrained optimization problem, while Section~\ref{intro:grad-flow} 
    recasts it as a gradient-flow dynamical system, proves well-posedness, and shows that its equilibria coincide with the stationary
    points of the objective. Further phase-space analysis yields a constructive method for solving the original problem.  
    The concept of an \emph{optimization scheme} is then formalized, accompanied by illustrative examples that recover 
    classical results for gradient descent. Finally, Section~\ref{intro:problems} enumerates the benchmark test functions
    considered in this study.

    \medskip

    \textbf{Organization of the paper.} Section~\ref{sec:theory} develops a theoretical framework for classifying critical 
    points using dynamical systems, Morse theory, and spectral analysis of $\nabla^2 f(\vct{x}^*)$. Section~\ref{sec:problems} 
    details our problem selection criteria and introduces the benchmark problems under study. In Section~\ref{sec:experiments}, 
    we present numerical experiments for each problem, describe our methodology for determining strict local minimizers $\vct{x}^*$,
    and outline our sampling-based convexity classification algorithm. Finally, Section~\ref{sec:conclusion} summarizes our findings, 
    offers practical recommendations, and discusses directions for future work.

    \medskip

    \newpage

    % Intro - Preliminaries
    \subsection{Preliminaries}
        \label{intro:preliminaries}
        \medskip 

        We use the notation defined in the Appendix~\ref{notation} as used by 
        Nocedal and Wright~\cite{NocedalAndWright06}.

        \medskip

        \begin{assumption}[Standing Assumptions]
            \label{assumption:standing}
            \begin{enumerate}\
                \item \textbf{Domain.} $\Omega \subset \R^n$ is path-connected, bounded, and open, and its
                boundary $\partial\Omega$ is a $C^{k}$ ($k\ge1$) embedded hypersurface.
                \item \textbf{Manifold structure.} The closure $\overline{\Omega}=\Omega\cup\partial\Omega$ is
                compact and carries the structure of a $C^{k}$ manifold with boundary~$\partial\Omega$.
                \item \textbf{Objective function.} The objective satisfies $f\in C^{k}(\overline{\Omega})$ 
                with $k \ge 2$, so, $f$, $\nabla f$, and $\nabla^{2}f$ extend continuously to~$\partial\Omega$. 
            \end{enumerate}
        \end{assumption}
        
        \td{
            TODO
            - Add $\rho$-Hessian Lipschitz and $\ell$-smooth assumptions? 
            - Critical Point Non-Degeneracy? 
            - Path-Connectedness of $\Omega$? Allows us to assume that $f$ is convex
              of on sublevel sets... needed for morse theory and further results in dynamical systems,
              e.g., gradient flow retracts sub-level sets onto unstable manifolds..
        }

    % Intro - Unconstrained Optimization Problem
    \subsection{Unconstrained Optimization Problem}
        \label{intro:unc-problem}

        \medskip 

        Consider the general form of a \textbf{smooth unconstrained optimization problem}
        \begin{equation}
            \min_{\vct{x} \in \mathbb{R}^n} f(\vct{x}), \label{eq:unconstrained-opt}
        \end{equation}
        where $\vct{x} \in \R^n$ is the optimization variable and $f: \R^n \rightarrow \R$ is
        a twice continuously differentiable objective function.    

        If a solution of \eqref{eq:unconstrained-opt} exists, then we denote the 
        \textbf{optimal value} and \textbf{optimal solution} as
        \begin{flalign*}
            \vct{x}^{*}\in\arg\min_{\vct{x}}f(\vct{x})
            \quad \text{ and } \quad
            f^* = \mathop{\mathrm{min}}_{\vct{x} \in \R^n} f(\vct{x}),
        \end{flalign*}
        respectively. The optimal value $f^*$ is the minimum value of $f$ over the entire domain $\R^n$.\\    

        In practice, we choose $\Omega$ in accordance with our standing assumptions~\ref{assumption:standing} 
        to contain all iterates and gradient-flow trajectories under consideration.
        By Heine–Borel, the closed and bounded set $\overline{\Omega}$ is compact, so the
        extreme-value theorem guarantees that the continuous real-valued function $f$ 
        attains its maximum and minimum on~$\overline{\Omega}$; where continuity of $f$ on 
        $\overline\Omega$ is guaranteed by the standing $C^k$ assumption of $f$. So by our 
        choice of $\Omega$, we can make global optimality claims about the optimal value 
        within our chosen domain. 

        \medskip
        
        A point satisfying the first-order optimality condition is called a \emph{critical point}. 
        Such a point can be a local minimizer, local maximizer, or saddle point. We classify critical 
        points as follows (cf.~\cite{NocedalAndWright06}):
        \begin{itemize}
            \item A \emph{local minimizer} if there exists a neighborhood $N$ of $\vct{x}^*$ such that 
            $f(\vct{x}^*) \leq f(\vct{x})$ for all $\vct{x} \in N$.
            \item A \emph{strict local minimizer} if there exists a neighborhood $N$ of $\vct{x}^*$ 
            such that $f(\vct{x}^*) < f(\vct{x})$ for all $\vct{x} \in N \setminus \{\vct{x}^*\}$.
            \item An \emph{isolated local minimizer} if there exists a neighborhood $N$ of 
            $\vct{x}^*$ such that $\vct{x}^*$ is the unique local minimizer in $N$.
            \item A \emph{global minimizer} if $f(\vct{x}^*) \leq f(\vct{x})$ for all $\vct{x} \in \R^n$.
        \end{itemize}

        Since we focus on nonlinear objective functions, global optimality generally cannot be 
        guaranteed. However, local optimality of a critical point $\vct{x}^*$ is verified using 
        the following conditions:
        \begin{flalign*}
            \text{Necessary:} \quad  & \nabla f(\vct{x}^*) = 0 ~ \text{ and } ~ \nabla^2 f(\vct{x}^*) \succeq 0\\
            \text{Sufficient:} \quad & \nabla^2 f(\vct{x}^*) \succ 0. 
        \end{flalign*}

        The necessary condition for $\vct{x}^*$ to be a local minimizer of $f$ is that 
        $\vct{x}^*$ satisfies the first-order and second-order optimality conditions.
        The \emph{second-order} optimality condition states that the Hessian of $f$ 
        is positive semidefinite at $\vct{x}^*$. If the Hessian is strictly positive
        definite at $\vct{x}^*$, it is both a necessary and a sufficient condition that $\vct{x}^*$
        is a strict local minimizer. It holds that strict local minimizers are isolated,
        corresponding precisely to points where $f$ is strictly convex.\\
    
    % Intro - Continuous Model
    \subsection{Continuous Model}
        \label{intro:grad-flow}
        \medskip

        We reinterpret the minimization problem~\eqref{eq:unconstrained-opt} as the search for equilibria 
        of the \emph{gradient flow} dynamical system. Interpreting our problem as a dynamical system 
        allows us to:

        \begin{itemize}
            \item exploit geometric structure when analyzing the critical-point landscapes;
            \item design time-discretisations of the gradient flow ODE~\eqref{eq:gradient-flow}
            and construct error bounds using the continuous model;
            \item leverage the stability theory of autonomous ODEs on compact manifolds.
        \end{itemize}

        In this section, we establish a link between the minimization of $f$ and the 
        trajectories of a dynamical system.

        \begin{definition}
            \label{def:grad-flow}
            The \emph{gradient‐flow} dynamical system is defined by the IVP 
            \begin{equation}
                \label{eq:gradient-flow}\tag{GF}
                \vct{\gamma}'(t) = -\nabla f\bigl(\vct{\gamma}(t)\bigr) ~\text{ subject to } \vct{\gamma}(0) = \vct{x}_0 \in \overline\Omega
            \end{equation}
            An integral curve $\vct{\gamma}:[0,\infty)\to\overline{\Omega}$ satisfying the \emph{gradient-flow} IVP is a gradient \emph{flow-line}, or, \emph{trajectory}.
        \end{definition}

        \medskip

        Suppose the initial point $\vct{x}_0$ is a critical point, then the gradient flow ODE 
        is satisfied by the constant trajectory $\vct{\gamma}(t) = \vct{x}_0$ for any time $t$. 
        Notice that constant $\vct{\gamma}(t)$ implies $\vct{\gamma}'(t) = \vct{0}$, substituting
        into the gradient-flow ODE asserts that $-\nabla f(\vct{x}_0) = \vct{0}$, which holds true
        since $\vct{x}_0$ is a critical point (i.e., $\nabla f(\vct{x}_0) = \vct{0}$).
        Consequently, the existence of a solution holds when $\vct{x}_0$ is a critical point
        and such points correspond to stationary equilibria in the gradient flow ODE phase space.
        Now we show equation \eqref{eq:gradient-flow} is well-posed for all $\vct{x}_0 \in \overline{\Omega}$.

        \medskip

        Let $\vct{\gamma}_{\vct{x}_0}$ be any gradient \emph{flow-line} starting at
        some point $\vct{x}_0$ in $\overline{\Omega}$. Note that the trajectory $\vct{\gamma}_{\vct{x}_0}$ 
        is driven by the steepest descent direction of the objective function $f$. But $f$ is bounded
        below by the minimum value $f^*$, so the trajectory $\vct{\gamma}_{\vct{x}_0}$ cannot
        escape the compact set $\overline{\Omega}$ in finite time. Indeed, we will show that the trajectory 
        $\vct{\gamma}_{\vct{x}_0}$ is guaranteed to converge to a critical point of $f$ in $\overline{\Omega}$.
        But first we must establish the IVP~\eqref{eq:gradient-flow} is well-posed for all $\vct{x}_0 \in \overline{\Omega}$.

        \begin{theorem}[Existence]\label{thm:gf-existence}
            For every $\vct{x}_0\in \overline{\Omega}$ the IVP \eqref{eq:gradient-flow} admits a
            unique solution $\vct{\gamma}_{\vct{x}_0}\in C^{1}\bigl([0,\infty);\overline{\Omega}\bigr)$
            that exists for all time $t\ge0$.
        \end{theorem}

        \begin{proof}[Sketch]
            Our standing assumptions imply that $-\nabla f$ is globally Lipschitz on the compact set $\overline{\Omega}$,
            i.e., $-f$ is $\ell$-smooth since $\nabla f$ is continuous on $\overline{\Omega}$. (ref appendix for
            $\ell$-smoothness definition). The Picard-Lindelöf theorem guarantees the existence of a unique
            solution $\vct{\gamma}_{\vct{x}_0}$ to the IVP \eqref{eq:gradient-flow} for some finite amount of time.
            The following Theorem~\ref{thm:flow-props} shows that the solution exists for all time $t\ge0$,
            namely, that the trajectory $\vct{\gamma}_{\vct{x}_0}(t)$ and remains in the compact set $\overline{\Omega}$ for all $t\ge0$.
        \end{proof}

        \begin{remark}
            In our proof of Theorem~\ref{thm:gf-existence} we assumed $f$ and $-\nabla f$ are defined 
            on all of $\mathbb R^n$, so that trajectories are well defined globally; we only 
            observe them on our chosen domain $\overline\Omega$. 
            We commit such theoretical shortcuts knowingly, as our shortcut is pathed when we introduce the
            assumption that $\Omega$ is path-connected, which ensures convexity of $f$ on the sublevel set
            $L_{f(\vct{x}_0)}^-$, so that the gradient flow ODE is well-defined on the entire sublevel set.
        \end{remark}

        The following lemma characterizes the monotonicity of $f$ along the trajectory $\vct{\gamma}_{\vct{x}_0}$.

        \begin{lemma}\label{lem:monotone-flow}
            Along any trajectory $\vct{\gamma}_{\vct{x}_0}(t)$ one has
            \begin{equation}\label{eq:monotone-flow}
                \frac{d}{dt}f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr) = -\|\nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr)\|^{2}\;\le\;0, \quad t \ge 0.
            \end{equation}
            Hence $f\circ\vct{\gamma}_{x_0}$ is non‐increasing in $t$, and strictly decreasing whenever $\nabla f(\vct{\gamma}_{\vct{x}_0}(t))\neq0$.
        \end{lemma}

        \begin{proof}
            Differentiating the composition $f\circ\vct{\gamma}_{\vct{x}_0}$ w.r.t. $t$ using 
            the chain rule yields
            \begin{flalign*}
                \frac{d}{dt}f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr) & = \nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr) \cdot 
                    \frac{d}{dt}\vct{\gamma}_{\vct{x}_0}(t)\\
                & = \nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr) \cdot \vct{\gamma}'_{\vct{x}_0}(t) \\
                & = \nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr) \cdot \left(-\nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr)\right)\\
                & = \langle \nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr), -\nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr) \rangle\\
                & = -\langle \nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr), \nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr) \rangle\\
                & = -\|\nabla f\bigl(\vct{\gamma}_{\vct{x}_0}(t)\bigr)\|^{2} \\
                & \leq 0.
            \end{flalign*}
            A direct consequence of the positive-definiteness property of a norm is that the final inequality
            is strict for all points $\vct{\gamma}_{\vct{x}_0}(t)$ that aren't critical.
        \end{proof}

        \begin{theorem}[Properties of the gradient flow]\label{thm:flow-props}
            Let $\vct{x}_0\in\overline{\Omega}$ and let
            $\vct{\gamma}_{\vct{x}_0}:[0,\infty)\to\overline{\Omega}$
            be the unique solution of \eqref{eq:gradient-flow}. Then
            \begin{enumerate}
            \item\label{item:continuity}
                    The flow map $(\vct{x}_0,t)\mapsto\vct{\gamma}_{\vct{x}_0}(t)$
                    is continuous in both variables.
            \item\label{item:accum}
                    Every accumulation point of $\vct{\gamma}_{\vct{x}_0}(t)$ as $t\to\infty$
                    belongs to $\operatorname{crit}(f)$.
            \end{enumerate}
        \end{theorem}

        \begin{proof}
            Suppose, to the contrary, that some accumulation point $\vct{x}^{*}$ satisfies
            $\nabla f(\vct{x}^{*})\neq 0$. FIXME: After re-structuring assumptions; reference
            prior remark.
        \end{proof}

        \newpage


    % Intro - Optimization Schemes
    \subsection{Optimization Schemes}
        \label{intro:scheme}
        \medskip

        We introduce a \emph{scheme} for solving a \emph{unconstrained optimization problem} based on the \emph{gradient flow}
        dynamical system~\ref{def:grad-flow}.

        \begin{definition}
            An \textbf{optimization scheme} is a one-parameter family of iteration operators
            $T_h : \overline{\Omega} \rightarrow \overline{\Omega}$, indexed by a step size 
            $h \in (0, h_0]$ where $h_0$ is constant, that generates an iterative sequence using the rule
            \begin{equation}
                \label{eq:scheme}
                \vct{x}_{k+1} = T_h(\vct{x}_k) \text{ for } k = 0, 1, 2, \ldots
            \end{equation}
            starting from an initial point $\vct{x}_0 \in \overline{\Omega}$. The scheme is well-defined such that the 
            triplet $(\vct{x}_0, h, T_h)$ satisfy:
            \begin{itemize}
                \item Consistency: $T_{h}$ is \emph{consistent of order $p\!\ge1$} with the flow~\eqref{eq:gradient-flow} if
                    $$
                        \bigl\|T_{h}(\vct{x})-\vct{x}+h\,\nabla f(\vct{x})\bigr\|
                        \;=\;\mathcal{O}\!\bigl(h^{p+1}\bigr)
                        \quad\text{as }h\to0,\;
                        \forall\,\vct{x}\in\overline{\Omega}.
                    $$
                    A consistent scheme approximates the continuous gradient flow w/ a local error of
                    $\mathcal{O}(h^{p+1})$ committed at each step $k$; where $p$ is the global order.
                    Consistent schemes reproduce the exact optimality condition in the limit as $h \to 0$.
                \item Stability: Let $\vct{x}^{*}\in\operatorname{crit}(f)$ be a \emph{strict} local minimizer.
                    The family $\{T_{h}\}$ is \emph{stable} at $\vct{x}^{*}$ if
                    $$
                        \exists\,c>0,\;h_{\max}>0,\;
                        \forall\,h\in(0,h_{\max}]:
                        \qquad
                        \rho\bigl(DT_{h}(\vct{x}^{*})\bigr)\le 1-ch,
                    $$
                    where $\rho(\cdot)$ denotes the spectral radius.  Equivalently,
                    $$
                        \|T_{h}(\vct{x})-T_{h}(\vct{y})\|\le(1-ch)\|\vct{x}-\vct{y}\|
                    $$
                    for all $\vct{x},\vct{y}$ in some neighborhood of $\vct{x}^{*}$.
                    A stable scheme is contractive in a neighborhood of $\vct{x}^{*}$, 
                    meaning that the distance between iterates shrinks by at least a 
                    factor of $1-ch$ at each step $k$.
            \end{itemize}
        \end{definition}

        \medskip 
            
        If a scheme is order-$p$ consistent and locally contractive at a strict
        minimizer $\vct{x}^{*}$, then for any fixed $h\in(0,h_{\max}]$
        the iterates satisfy
        $$
            \|\vct{x}_{k}-\vct{x}^{*}\|\le(1-ch)^{k}\|\vct{x}_{0}-\vct{x}^{*}\|,
        $$
        and hence $\vct{x}_{k}\to\vct{x}^{*}$ as $k\to\infty$.

        \medskip

        Table~\ref{tab:schemes} summarises four standard choices for $T_{h}$,
        stating their consistency order and the conditions under which local 
        contractivity holds; see, e.g., Nocedal-Wright~\cite{NocedalAndWright06}
        for detailed discussions of these schemes.

        \medskip
        \begin{minipage}{0.8\textwidth}
        \centering
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{@{}l l c c@{}}
            \toprule
            \textbf{Scheme} & 
            \textbf{Iteration operator $T_{h}(\vct{x})$} & 
            \textbf{Order $p$} & 
            \textbf{Stability near $\vct{x}^{*}$} \\ \midrule
            Gradient descent (GD) &
            $\vct{x}-h\,\nabla f(\vct{x})$ &
            1 &
            $\nabla^{2}f(\vct{x}^{*})\succeq \mu I\succ0,\; 0<h\le 1/\ell$ \\[3pt]

            Newton (NM) &
            $\vct{x}-h\,\nabla^{2}\!f(\vct{x})^{-1}\nabla f(\vct{x})$ &
            2 &
            $\nabla^{2}f(\vct{x}^{*})\succ0,\; 0<h\le 1$ \\[3pt]

            Quasi–Newton (QN) &
            $\vct{x}-h\,B_{k}\nabla f(\vct{x})$ \quad
            ($B_{k}\!\to\nabla^{2}\!f(\vct{x}^{*})^{-1}$) &
            1 &
            Same as NM once $B_{k}\succ0$ and $\|B_{k}\|$ is bounded \\[3pt]

            Trust region (TR) &
            $\displaystyle
            \vct{x}+\arg\min_{\|\vct{\tau}\|\le\Delta}
            m_{\vct{x}}(\vct{\tau})$ &
            2 &
            Same as NM for sufficiently small $\Delta$ \\ \bottomrule
        \end{tabular}
        \captionof{table}{
            Representative optimization schemes for problem~\eqref{eq:unconstrained-opt}. 
            ($\ell$ denotes the Lipschitz constant of $\nabla f$ on $\overline{\Omega}$).
        }
        \label{tab:schemes}
        \end{minipage} 
        
        
        \newpage

        \subsubsection*{Analysis of Gradient Descent (GD)}

            \begin{theorem} Assume $f$ is $\ell$-smooth and $\alpha$-strongly convex and that $\eps > 0$.
                If we iterate the gradient descent \emph{scheme} with $h = h_0 = \frac{1}{\ell}$ held fixed, i.e.,
                $$
                    T_{h}(\vct{x}_k) = \vct{x}_k - \frac{1}{\ell} \nabla f(\vct{x}_k),
                $$
                then $d(x_k, x^*) \leq \eps$ for all $k > K$ where $K$ is chosen to satisfy
                $$
                    \frac{2\ell}{\alpha} \cdot \log\left(\frac{d(x_0, x^*)}{\eps}\right) \leq K.
                $$
            \end{theorem}

            \begin{remark}
                Under \emph{$\ell$-smoothness} and \emph{$\alpha$-strong convexity} assumptions
                in a neighborhood $\Omega$ about $\vct{x}^*$, it may be shown directly from 
                the above theorem above that the \emph{GD scheme} converges linearly to 
                the optimal solution $\vct{x}^*$ at a rate of
                $$
                    \frac{d(\vct{x}_k, \vct{x}^*)}{d(\vct{x}_{k-1}, \vct{x}^*)} \leq 1 - \frac{\alpha}{\ell}
                $$
                where $d(\vct{x}_k, \vct{x}^*)$ is the distance between the current iterate $\vct{x}_k$ and 
                the optimal solution $\vct{x}^*$. The convergence rate is linear in the sense that the 
                distance between the current iterate and the optimal solution decreases by a factor of 
                $1 - \frac{\alpha}{\ell}$ at each iteration. (Ref: TODO)
            \end{remark}

            \begin{remark}
                Convergence to a first-order stationary point trivally
                implies convergence to a $\eps$-first-order stationary point.
                Similarly, convergence to a second-order stationary point trivially
                implies convergence to a $\eps$-second-order stationary point.
            \end{remark}

            \medskip

            \begin{theorem}
                Assume $f$ is $\ell$-smooth, then for any $\eps > 0$, if we iterate
                the GD scheme with $h = h_0 = \frac{1}{\ell}$ held fixed starting from
                $\vct{x}_0 \in \Omega$ where $\Omega$ is a neighborhood of $\vct{x}^*$,
                then the number of iterations $K$ required to achieve the stopping condition
                $\| \nabla f(\vct{x}_k) \| \leq \eps$ is at most
                $$
                    \left\lceil \frac{\ell}{\eps^{2}} \, (f(\vct{x}_0) - f(\vct{x}^*)) \right\rceil
                $$
            \end{theorem}

            \begin{remark}
                \textbf{TODO and Questions}
                \begin{itemize}
                    \item State how we use theorems in when performing analysis from
                    the results of our experimewts.
                    \item What is the relationship between $\ell$ and $\alpha$?
                    \item In practice do we know how to compute $\ell$ and $\alpha$?
                    \item What is the relationship between $\ell$ and $\rho$?
                    \item In practice do we know how to compute $\ell$ and $\rho$?
                \end{itemize}
            \end{remark}

        \medskip
    

    % Intro - Benchmark Problems
    \subsection{Benchmark Problems}
        \label{intro:problems}
        We select a subset of the \texttt{OptimizationProblems.jl}~\cite{OptimizationProblems}
        Julia package that support automatic differentiation (AD) natively through operator
        overloading. (TODO: Cite ForwardDiff.jl, Flux.jl, etc.) Each problem is implemented
        as \texttt{ADNLPModel} instance, which is a wrapper around the \texttt{NLPModel} interface
        whose backend AD engine is configurable to support forward-mode or reverse-mode.

        \td{todo:
            - ref overleaf document and introduction section
            - enumerate the problems
        }


% ------------------ Theory    
\section{Morse Theory}
    \label{sec:theory}
    
    \medskip

    Note that $\Omega$ is a bounded subset of $\R^n$, so its closure
    $\overline{\Omega} = \Omega \cup \partial \Omega$ is a compact subset
    of $\R^n$, by the Heine-Borel Theorem.
    Also, the boundary $\partial \Omega$ is sufficiently smooth,
    so we can apply the theory of smooth manifolds.
    The closure $\overline{\Omega}$ is a compact subset of $\R^n$ and
    is a smooth manifold with boundary $\partial \Omega$.
    The interior $\Omega$ is an open subset of $\R^n$ and is a smooth manifold.\\

    \td{Move the above bit to 1.3}

    \begin{definition}
            A point $\vct{x}^* \in \Omega$ is a \textbf{critical point} of $f$ if the
            differentiable map $df_p: T_p \Omega \rightarrow \R$ is zero. (Here
            $T_p \Omega$ is a tangent space of the Manifold $M$ at $p$.) 
            The set of critical points of $f$ is denoted by $\text{crit}(f)$.
    \end{definition}

    \begin{definition}
            A point $\vct{x}^* \in \Omega$ is a \textbf{non-degenerate critical point} of $f$ if
            the Hessian $H_p f$ is non-singular.
    \end{definition}

    \begin{definition}
            The \textbf{index} of a \emph{non-degenerate critical point} $\vct{x}^*$ is defined to be
            the dimension of the negative eigenspace of the Hessian $H_p f$.
            \begin{itemize}
                \item local minima at $\vct{x}^*$ have index $0$.
                \item local maxima at $\vct{x}^*$ have index $n$.
                \item saddle points at $\vct{x}^*$ have index $k$ where $0 < k < n$.
            \end{itemize}
            We reserve the integers $c_0, c_1, \dots, c_i, \dots, c_n$ to denote the number of
            critical points of index $i$.
    \end{definition}

    \begin{definition}
        A \textbf{Morse function} is a smooth function $f : \Omega \rightarrow \R$ such that
        all critical points of $f$ are non-degenerate.
    \end{definition}

    \subsection{Morse Theory in a Metric Space}

    \begin{theorem}
            Let $f$ be a Morse function on $\Omega$, then the Euler characteristic of $\Omega$ is
            given by
            $$
                \chi(\Omega) = \sum_{i=0}^n (-1)^i c_i
            $$
            where $c_i$ is the number of critical points of index $i$.
    \end{theorem}

    \begin{remark}
        The Euler characteristic $\chi(\Omega)$ is a topological invariant of the manifold $\Omega$
        and is independent of the choice of Morse function $f$.
        The Euler characteristic is a measure of the "shape" of the manifold and can be used to
        distinguish between different topological spaces.
        The Euler characteristic may be defined by the alternating sum of the Betti numbers
        $b_i$ of the manifold $\Omega$
        $$
            \chi(\Omega) = \sum_{i=0}^n (-1)^i b_i
        $$
        where $b_i$ is the $i$-th Betti number of the manifold $\Omega$.
    \end{remark}

    \begin{theorem}
        (Sard's theorem) Let $f$ be a Morse function on $\Omega$, then
        the image $f(\text{crit}(f))$ has Lebesque measure zero in $\R$.
    \end{theorem}

    \begin{remark}
        We state a particular instance of Sard's theorem for continuous scalar-valued functions $f$,
        which was first proved by Anothony P. Morse in 1939.
        The theorem asserts that the image of the critical points of a Morse function is a set 
        of measure zero in $\R$. This means that the critical points of a Morse function are "rare" in the sense that they
        do not form a dense subset of the manifold $\Omega$.
        Consequently, selecting $\vct{x} \in \Omega$ at random will almost never yeild a critical
        point of $f$.
    \end{remark}

    \begin{remark}
        The property that $\vct{x}^* \in \Omega$ being a \emph{critical point} of a Morse function $f$ is
        not dependent of the metric of $\Omega \subset \R^n$ (and consequently, the norm induced by the metric)
    \end{remark}

    \begin{theorem}
        For a Morse function $f$ on $\Omega$, the gradient of $f$ is either zero or
        orthogonal to the tangent space of the level set $L_c$ at $\vct{x} \in L_c$.
    \end{theorem}

    The above theorem implies that at a stationary point $\vct{x^*}$, a
    level set $L_{\vct{x^*}}$ is reduced to a single point
    when $\vct{x^*}$ is a local minimum or maximum. 
    Otherwise, the level set may have a singularity
    such as a self-intersection or a cusp.

    \subsection*{Signed Distance Function}
    \td{
        TODO: Add signed distance function theory notes and cite ref.
        The only reason to do this is to talk about geodesics,
        height parameterized flows, mean curvature flow, minimal
        surfaces and links to dimensionality reduction.
        Ref: Chapter 6? Stanley Osher and Ronald Fedkiw, Level 
        Set Methods and Dynamic Implicit Surfaces, Springer, 2003.
    }

    \textbf{Time Marching Level Set Methods}
        TODO: Explain how level set methods would allow us
        to classify the critical point structure of $f$.
        And their role in low-dimensional topology.
        Explain curse of dimensionality and how level set methods
        can be used to classify the critical point structure of $f$.
        Chapter 7? Osher and Fedkiw, Level Set Methods and Dynamic
        Implicit Surfaces, Springer, 2003.
    
    \textbf{Discontinuous Galerkin Methods / Transportation Methods}
        High dimensional sparse grid methods ... dependant on the sturcture
        of $f$. Reference recent work in optimal transport theory.

    \subsection{Machine Learning}
        Universal nonlinear approximation theorems and PINNS/Deep Learning
        methods. Have the luxury of economies of scale, however, they
        still suffer from the curse of dimensionality. Ref recent work
        on learning approximate level set flows in up to a dimension of 100.
        \textbf{TODO:} Interesting to think about learning the critical
        point structure of $f$ via a neural network in small dimensions..
        Ecspecially trace data, to help us better understand why some
        Quasi-Newton methods work better than others.

    \medskip

    % ------------------ PROBLEMS
    \section{Problem Selection Criterion and Software Stack}
        \label{sec:problems}
        \medskip


    % ------------------ Numerical Experiments
    \section{Numerical Experiments}
        \label{sec:experiments}
        \medskip
        An uniformed sampling of the problem space $\Omega$ is performed
        in Code Listings~\ref{lst:problem-sampling}.

    % ------------------ Conclusion
    \section{Conclusion}
        \label{sec:conclusion}
        \medskip
        \td{reference introduction section.}
        \medskip

    % ------------------ APPENDIX
    \newpage
    \section{Apendix}

    % ------------------ BIBLIOGRAPHY
    \bibliographystyle{alpha}
    \bibliography{../references}


\subsection*{Notation}
    
    We assume the following notation throughout

    \begin{itemize}
        \label{notation}
        \item $\| \cdot \|$ denotes the usual $\ell_2$ norm for vectors $\vct{x}$ in $\mathbb{R}^n$ and $p = 2$ norm
        for matrices in $\mathbb{R}^{n \times m}$. i.e.,
        \begin{flalign*}
            \|x\| & := \left(\sum_i x_i^2\right)^{1/2} \\
                \|A\| & := (\lambda_{\max}(A^\top A))^{1/2}
        = \max(\sigma(A))
        \end{flalign*}
        \item $\sigma(A) := \{\text{singular values of } A\}$.
        \item $A \in \mathbb{R}^{n\times n}$ $\implies ~ \sigma(A) = \{\text{eigenvalues of } A \text{ (i.e. spectrum)}\}$
        \item $\sigma_{\max}(A) := \max(\sigma(A))$ and $\sigma_{\min}(A) := \min(\sigma(A))$.
        \item $ A \in \mathbb{R}^{n\times n}$  $\implies \lambda_{\max}(A) := \sigma_{\max}(A)$ and $\lambda_{\min}(A) = \sigma_{\min}(A) $
        \item $\langle \cdot, \cdot \rangle$ denotes the usual inner product on $\mathbb{R}^n$, i.e.,
        $$
            \langle \vct{x}, \vct{y} \rangle := \vct{x}^\top \vct{y} = \sum_{i=1}^n \vct{x}_i \vct{y}_i = \| \vct{x} \| \|\vct{y}\| \cos(\theta)
        $$
        where $\theta$ is the angle between $\vct{x}$ and $\vct{y}$.
        \item $\mathcal{B}_r(\vct{x}) := \{ \vct{y} \in \mathbb{R}^n : \|\vct{y} - \vct{x}\| < r \}$ is the open ball of 
        radius $r$ centered at $\vct{x} \in \R^n$.
        \item $\text{crit}(f) = \{ \vct{x}^* \in \R^n : \nabla f(\vct{x}^*) = 0 \}$ is the set of critical points of $f$.
    \end{itemize}


\subsection{Definitions}
    \label{sec:definitions}
    
    \td{TODO: integrated into article as needed. At a minimum labled and references}

    % Lipschitz
    \begin{definition}
        $f$ is \textbf{$L$-Lipschitz} if $\forall ~ \vct{x_1},\vct{x_2}$
        $$
        \; \exists~ L \geq 0 ~:~  \| f(\vct{x_1}) - f(\vct{x_2})\| 
        \leq L\|\vct{x_1} - \vct{x_2}\|
        $$
    \end{definition}

    % L-Lipschitz gradient
    \begin{definition} 
        $f$ has \textbf{$\ell$-Lipschitz gradient}, or, $f$ is \textbf{$\ell$-smooth} if
        $\forall ~ \vct{x_1},\vct{x_2}$
        $$
            \exists~ \ell \geq 0 ~:~ \|\nabla f(\vct{x_1}) - \nabla f(\vct{x_2})\| 
            \leq \ell\|\vct{x_1} - \vct{x_2}\|
        $$
    \end{definition}

    % Rho Lipschitz Hessian
    \begin{definition}
        $f$ has \textbf{$\rho$-Lipschitz Hessian} if $\forall ~ \vct{x_1},\vct{x_2}$
        $$
            \; \exists~ \rho \geq 0 ~:~ \|\nabla^2 f(\vct{x_1}) - \nabla^2 f(\vct{x_2})\| 
            \leq \rho\|\vct{x_1} - \vct{x_2}\|
        $$
    \end{definition}

    % Convexity
    \begin{definition}
        $f$ is \textbf{convex} if $\forall ~ \vct{x_1},\vct{x_2}$
        \begin{flalign*}
            f(\vct{x_2}) & \geq f(\vct{x_1}) + \langle  \vct{x_2} - \vct{x_1}, \nabla f(\vct{x_1}) \rangle\\
                        & = f(\vct{x_1}) + \nabla f(\vct{x_1})^T(\vct{x_2} - \vct{x_1}) 
        \end{flalign*}
    \end{definition}

    % Strictly Convex
    \begin{definition}
        $f$ is \textbf{strictly convex} if
        \begin{flalign*}
            \exists~ \mu > 0 ~ : ~ & \nabla^2 f \succeq \mu I \\ 
            & \iff \lambda_{\min}(\nabla^2 f) \geq \mu > 0 
        \end{flalign*}
    \end{definition}

    % Alpha strong convexity
    \begin{definition}
        $f$ is \textbf{$\alpha$-strongly convex} if $\forall ~ \vct{x_1},\vct{x_2} \exists~ \alpha > 0$ s.t.
        \begin{flalign*}
            & f(\vct{x_2}) \geq f(\vct{x_1}) + \langle \nabla f(\vct{x_1}), \vct{x_2} - \vct{x_1} \rangle + 
            \frac{\alpha}{2}\|\vct{x_2} - \vct{x_1} \|^2\\
            & \iff \lambda_{\min}(\nabla^2 f (\vct{x})) \geq - \alpha. 
        \end{flalign*}
    \end{definition}

    % First-order stationary point
    \begin{definition}
        $\vct{x^*}$ is a \textbf{first-order stationary point}
        if $\| \nabla f(x^*) \| = 0$.
    \end{definition}

    % Eps-first-order stationary point
    \begin{definition}
        $\vct{x^*}$ is an \textbf{$\eps$-first-order stationary point} 
        if $\|\nabla f(x^*)\| \leq \eps$. 
    \end{definition}

    % Second-order stationary point
    \begin{definition}
        $\vct{x}^* \in \R^n$ is a \textbf{second-order stationary point} if 
        $\| \nabla f(x^*) \| = 0\text{ and } \nabla^2 f(x^*) \succeq 0$.
    \end{definition}

    % Eps-second-order stationary point
    \begin{definition}
        if $f$ has $\rho$-Lipschitz Hessian, $\vct{x}^* \in \R^n$ is a
        \textbf{$\eps$-second-order stationary point} if 
        $$
            \| \nabla f(x^*) \| \leq \eps \text{ and }\nabla^2 f(x^*) \succeq -\sqrt{\rho \eps}
        $$
        \begin{remark}
            Note that the Hessian is not required to be positive definite, 
            but it is required to have a small eigenvalue. 
        \end{remark}
    \end{definition}

    \begin{definition}
        A point $\vct{x^*} \in \Omega$ is a \textbf{critical point} of $f$ if the
        differentiable map $df_p: T_p \Omega \rightarrow \R$ is zero. (Here
        $T_p \Omega$ is a tangent space of the Manifold $M$ at $p$.) 
        The set of critical points of $f$ is denoted by $\text{crit}(f)$.
    \end{definition}

    \begin{definition}
        A point $\vct{x^*} \in \Omega$ is a \textbf{non-degenerate critical point} of $f$ if
        the Hessian $H_p f$ is non-singular.
    \end{definition}

    \begin{definition}
        The \textbf{index} of a \emph{non-degenerate critical point} $\vct{x^*}$ is defined to be
        the dimension of the negative eigenspace of the Hessian $H_p f$.
        \begin{itemize}
            \item local minima at $\vct{x^*}$ have index $0$.
            \item local maxima at $\vct{x^*}$ have index $n$.
            \item saddle points at $\vct{x^*}$ have index $k$ where $0 < k < n$.
        \end{itemize}
        We reserve the integers $c_0, c_1, \dots, c_i, \dots, c_n$ to denote the number of
        critical points of index $i$.
    \end{definition}

    \begin{remark}
        For each objective function $f$ we are interested in determining the
        critical points of $f$ 
    \end{remark}

    \begin{remark}
        The \textbf{Morse function} is a smooth function $f : \Omega \rightarrow \R$ such that
        all critical points of $f$ are non-degenerate.
    \end{remark}


% ------------------ TEST PROBLEMS
\subsection{Test Problems}

\include{test-set}

% ------------------- Code Listings
\subsection{Code Listings}

The following code is available in the source code 
repository~\hyperlink{repository}{https://github.com/danphenderson/numerical-optimization/blob/main/julia/saddles.jl}
\lstset{basicstyle=\ttfamily, columns=fullflexible, keepspaces=true, breaklines=true}

\lstset{language=julia}
\begin{lstlisting}[language=julia, caption={Algorithm 16.5}, label={lst:problem-sampling}]
using CSV, DataFrames, OptimizationProblems, ADNLPModels, NLPModels
using Random, Arpack, Optim, LineSearches
using LinearAlgebra, Statistics, Distributions

Random.seed!(1234)


function get_test_set(n::Int=40)
    """
    List of unconstrained scalable ADNLPModels within OptimizationProblems.jl
    """
    # meta = OptimizationProblems.meta
    # names_pb_vars = meta[
    # (meta.variable_nvar .== true) .& (meta.ncon .== 0) .& (5 .<= meta.nvar .<= 100),
    #     [:nvar, :name]
    # ]
    # test_set_generator = (
    #     eval(Meta.parse("ADNLPProblems.$(pb[:name])(n=$n)")) for pb in eachrow(names_pb_vars)
    # )
    # return [p for p in test_set_generator]
    return [
	"genrose",
	"arglina",
	"freuroth",
	"eg2",
	"cosine",
	"arglinb",
	"arglinc",
	"argtrig",
	"arwhead",
	"bdqrtic",
	"brownal",
	"broyden3d",
	"chnrosnb_mod",
	"cragglvy",
	"cragglvy2",
	"curly10",
	"curly10",
	"curly20",
	"curly30",
	"dixon3dq",
	"dqdrtic",
	"dqrtic",
	"edensch",
	"engval1",
	"errinros_mod",
	"extrosnb",
	"fletcbv2",
	"fletcbv3_mod",
	"fletchcr",
	"genhumps",
	"genrose_nash",
	"indef_mod",
	"integreq",
	"liarwhd",
	"morebv",
	"noncvxu2",
	"noncvxun",
	"nondia",
	"nondquar",
	"penalty1",
	"penalty2",
	"penalty3",
	"power",
	"quartc",
	"sbrybnd",
	"schmvett",
	"scosine",
	"sinquad",
	"tointgss",
	"tquartic",
	"tridia",
	"vardim"];
end

function get_problem(name::String, n::Int=40)
    """
    Get a problem by name
    """
    return eval(Meta.parse("ADNLPProblems.$(name)(n=$n)"))
end

function get_optim_options()
    """
    Using really stict conditions in low dimensions.

    Tacking earlier in routine may be obpuscated by extra
    iterations to obtain terminal convergence.
    """
    return Optim.Options(
        iterations = 10000000,
        g_abstol = eps(),       
        store_trace = false, # Trace has a lot of useful stuff...
        show_trace = false,
        extended_trace = false,
    )
end

function build_sample_box(problem::ADNLPModel)
    """ 
    Box centered around the minimizer
    """
    x0 = problem.meta.x0
    scale_vector = 2 .* abs.(x0)
    scale_vector[scale_vector .<= 1.0] .= 1.0
    return scale_vector
end

function pull_sample(problem, box::Vector)
    """
    Pulls a sample uniformly from the box box surrounding x0
    """
    return rand.(Uniform.(-box, box))
end

function bfgs_linesearch()
    """
    Define the algorithm for the optimization
    """
    return BFGS(;
        alphaguess = LineSearches.InitialStatic(),
        linesearch = LineSearches.HagerZhang(),
        initial_invH = x -> Matrix{eltype(x)}(I, length(x), length(x)),
        manifold = Flat(),
    )
end

function gradiant_descent_linesearch()
    """
    Defines the Quasi-Newton algorithm for the optimization.

    P is our H. Currently P = \nabla^2 f(x) = I and we fallback
    to gradient descent. 
    
    TODO: Accept P as an argument.
    """
    GradientDescent(; 
        alphaguess = LineSearches.InitialHagerZhang(),
        linesearch = LineSearches.HagerZhang(),
        P = nothing,
        precondprep = (P, x) -> nothing
    )
end

function newton_trust_region()
    """
    Defines the Newton Trust Region algorithm for the optimization.
    """
    return NewtonTrustRegion(; initial_delta = 1.0,
        delta_hat = 100.0,
        eta = 0.1,
        rho_lower = 0.25,
        rho_upper = 0.75)
end

function eigs_hess(problem::ADNLPModel, x_cp::Vector)
    H = hess(problem, x_cp)
    λ, _ = eigs(H, nev=problem.meta.nvar - 1, maxiter=10000, which=:LM)
    λmin, _ = eigs(H, nev=1, maxiter=10000, which=:SR)
    push!(λ, pop!(λmin))
    return λ
end

function run_sample(problem::ADNLPModel, sample::Vector)
    """
    Run the optimization algorithm on the problem
    """
    # Define objective and in-place gradient aligning with optim's interface.
    x0 = sample
    f(x) = obj(problem, x)
    g!(G, x) = grad!(problem, x, G)
    h!(H, x) = hess!(problem, x, H)

    # Run the optimization
    res = Optim.optimize(
        f, 
        g!, 
        x0, 
        bfgs_linesearch(),
        get_optim_options()
    )

    # Reset problem counters.
    NLPModels.reset!(problem)
    return res
end

function run(problem)
    box = build_sample_box(problem)
    df = DataFrame(
        "initial_objective" => Vector{Float64}(),
        "final_objective" => Vector{Float64}(), 
        "g_residual" => Vector{Float64}(),
        "is_saddle" => Vector{Bool}(),
        "pos_curvature_directions" => Vector{Int}(),
        "neg_curvature_directions" => Vector{Int}(),
        "zero_curvature_directions" => Vector{Int}(),
        "max_lambda" => Vector{Float64}(),
        "min_lambda" => Vector{Float64}(),
        "median_lambda" => Vector{Float64}(),
        "iterations" => Vector{Int}(),
        "critical_point" => Vector{Vector{Float64}}(),  
    )
    for _ in 1:1000
        sample = pull_sample(problem, box)
        fx0 = obj(problem, sample)
        try
            res = run_sample(problem, sample)
            if !res.f_converged
                continue
            end
            λ = eigs_hess(problem, res.minimizer)
            push!(df, (
                initial_objective = fx0,
                final_objective = res.minimum,
                g_residual = res.g_residual,
                is_saddle = λ[end] < 0,
                pos_curvature_directions = sum(λ .> 0),
                neg_curvature_directions = sum(λ .< 0),
                zero_curvature_directions = sum(abs.(λ) .< 1e-12),
                max_lambda = maximum(λ),
                min_lambda = minimum(λ),
                median_lambda = median(λ),
                iterations = res.iterations,
                critical_point = res.minimizer,
            ))
        catch
            continue
        end
    end
    return df
end

function unique_critical_points(df::DataFrame)
    """
    Compares the critical points locations to determine
    the number of unique critical points.
    """
    critical_points = df.critical_point
    critical_points = [round.(x, digits=4, base=2) for x in critical_points] # HACK d
    return length(unique(critical_points))
end

function run_all()
    test_set = get_test_set()
    mkpath("public/saddles/dim-40")
    for pb in test_set
        problem = get_problem(pb, 40)
        df = run(problem)
        CSV.write("public/saddles/dim-40/$(pb).csv", df)
        println("$(pb) has $(unique_critical_points(df)) unique critical points.")
        println("   $(pb) total saddles $(sum(df.is_saddle))")
    end
end
\end{lstlisting}
\newpage



\end{document}