{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trust-Region (TR)\n",
    "\n",
    "\n",
    "### Overview\n",
    "TR methods define a region around the current iterate wich they trust a _model function_ to be a good representation of the objective function, and choose the step to be the approximate minimizer of the model in this region.\n",
    "Thus, the step and direction on choosen by the minimization in the region.\n",
    "In general, the _model function_ $m_k$ that is used at the $x_k$ iterate is the quadratic model from the Taylor-series expansion of the objective function $f$ around $x_k$, i.e.  \n",
    "\n",
    "$$f(x_k + p) = f_k +g_k^T p + \\frac12p^T \\nabla^2 f(x_K + tp) p $$  \n",
    "\n",
    "where scalar $t$ is in $(0,1)$ and $g_k = \\nabla f(x_k)$.\n",
    "For ease of computation, we generally approximate the Hessian $\\nabla^2 f(x_K + tp)$ with a symmetric matrix $B_k$. Then our model function $m_k$ becomes  \n",
    "\n",
    "$$m_k(p) = f_k + g^T_k p + \\frac12p^TB_kp, $$  \n",
    "and by the definition of $t$, our introduction of $B_K$, and our use of second-order Taylor Series Truncation, we expect $||f(x_k + p)-m_k(p)|| \\approx O(||p||^2)$.\n",
    "When $B_k = \\nabla^2f(x_k)$, as it does in a TR Newton method, $O(||p||^3)$, which is very small when $p$ is small; however, we are concerned about quasi-Newton methods. Then to obtain each step to progress to the $x_{k+1}$ iterrate, we seek a solution of the subproblem  \n",
    "\n",
    "$$ \\min_{p\\in\\mathbb{R^n}} m_k(p) = f_k + g^T_k p + \\frac12 p^T B_k p ~ : ||p|| \\leq \\Delta_k, $$  \n",
    "where $\\Delta_k$ is a choosen trust region radius at the $k$th step.\n",
    "We refer to the solution our minimization problem as $p_k^*$.\n",
    "Note, when $||\\cdot||$ is not given a subscript we are reffering to the Euclidean norm.\n",
    "Thus, our constraint condition $||p|| \\leq \\Delta_k$ is equivalent to $p^Tp \\leq \\Delta_k^2$.\n",
    "- When B_k is positive definite, such as in a steepest descent or a Newton direction for a Linear objective function, we have an analytic solution, i.e. $p_k^* = -B_k^{-1} g_k.$  \n",
    "\n",
    "### Selection of TR Radius, $\\Delta_k$   \n",
    "We use the information at the $k-1$ iteration to determine the trust-region radius on the $kth$ iteration.  \n",
    "Specifically, we compute the ratio of the _actual reductions_ to the _predicted reduction_ as given by  \n",
    "\n",
    "$$ \\rho_k = \\frac{f(x_k) - f(x_k + p_k^*)}{m_k(0) - m_k(p_k^*)}. $$  \n",
    "Since $p^*_k$ is determined over a region that includes $p = \\vec{0}$, and $p_k^*$ is a minimizer of $m_k$ in $\\Delta_k$, our _predicted reduction_ will always be nonnegative.  \n",
    "\n",
    "From this we infer, if $\\rho_k$ is negative it is a consequence of the numerator and that $f(x_k + p^*_k) > f(x_k)$. And if we enforce our TR scheme to be _monotone_, i.e. $f(x_k) < f(x_{k-1})$, we must reject our current step of $x_k + tp^*_k$ and perform the subproblem again with a smaller $\\Delta_k$.\n",
    "Similarly, we can accept any positive valule of $\\rho_k$ with saftery that our scheme is monotone. If $\\rho_k$ is close to $1$, it is the case that $m_k$ did a satisfactory job of approximating $f$ over our trust region and we should increase our trust-region radius at the next iteration.\n",
    "If $\\rho_k$ is small and positive, we should shrink $\\Delta_k$ at the next iteration. \n",
    "\n",
    "The following algorithm, `tr(..)` conforms to our described selection process, but we must have a means to solve $p^*_k$ before we can implement it.  \n",
    "\n",
    "### Trust-Region Subproblem  \n",
    "As in a line-search, we can approximate $p_k^*$ and still preserve global convergence as long as $p_k^*$ gives a _sufficient reduction_ in the model function. One simple procedurce is to calculate the Cauchy point, which is inexpensive, robust, and does a satisfactory job. This is performed below, in the implementation sketch of `tr(..)`. Note, there are many improvents to the Cauchy point method, building upon it while exploiting properties of $B_k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "Takes a radius, a max radius, an objective function f, and a starting guess for x^*  \n",
    "\n",
    "function tr(Δk, ΔM, f, x)  \n",
    "\n",
    "    while # TODO stop criterion   \n",
    "        # TODO calculate gk, Bk, fk, m = (x) -> ...  \n",
    "        \n",
    "        # Cauchy point approx p*_k as p  \n",
    "        gk_norm = norm(gk)   \n",
    "        tau = gk' * Bk * gk # currently a place holder  \n",
    "        if tau <= 0         # then mk is not convex quadratic  \n",
    "            tau = 1  \n",
    "        else  \n",
    "            tau = min(gk_norm^3/(Δk * tau), 1)  \n",
    "        end  \n",
    "        p = -tau Δk / gk_norm * gk  \n",
    "        \n",
    "        # Handle step selection  \n",
    "        rho = (f(x) - f(x + p)) / (m(0) - m(p))  \n",
    "        if rho =< 0.25  \n",
    "            Δk = 0.25 * Δk  \n",
    "        elseif rho > 0.75 && norm(rho) ≈ Δk # else we don't increase Δk  \n",
    "            Δk = min(2*Δk, ΔM)  \n",
    "        end  \n",
    "        \n",
    "        # Update xk if it makes sense (upper bound can be reduced)  \n",
    "        if rho < 0.25 # else don't update xk, reject and perform iteration again at reduced Δk  \n",
    "            xk += p  \n",
    "        end    \n",
    "    end  \n",
    "    x # returns a global minimizer  \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
